{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf5ffbf-11ea-4fcc-b22e-3a678597a632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from scipy.special import expit\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Social_Network_Ads.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54ae7b09-a11f-41f8-967a-072a568e7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels\n",
    "X = df.drop(['User ID', 'Gender', 'Purchased'], axis=1)\n",
    "y = df['Purchased']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c372ec9d-a099-4fc9-b77c-a51e1abc1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scalers\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Scale the features using raw data, normalization, and standardization\n",
    "X_train_raw = X_train.copy()\n",
    "X_test_raw = X_test.copy()\n",
    "\n",
    "X_train_norm = min_max_scaler.fit_transform(X_train)\n",
    "X_test_norm = min_max_scaler.transform(X_test)\n",
    "\n",
    "X_train_std = standard_scaler.fit_transform(X_train)\n",
    "X_test_std = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60c09f20-f68a-4fea-a7cd-6906be06e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return expit(z)\n",
    "\n",
    "# Define the cost function\n",
    "def cost_function(h, y):\n",
    "    epsilon = 1e-10  # a small value to avoid zero or one in the logarithm\n",
    "    return (-y * np.log(h + epsilon) - (1 - y) * np.log(1 - h + epsilon)).mean()\n",
    "\n",
    "# Define the logistic regression function\n",
    "def logistic_regression(X, y, alpha, num_iter, intercept=False):\n",
    "    # Add an intercept term if needed\n",
    "    if intercept:\n",
    "        X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "    \n",
    "    # Initialize the coefficients\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    \n",
    "    # Initialize the cost history\n",
    "    cost_history = []\n",
    "    \n",
    "    # Perform gradient descent\n",
    "    for i in range(num_iter):\n",
    "        # Compute the linear combination of features and coefficients\n",
    "        z = np.dot(X, theta)\n",
    "        \n",
    "        # Compute the sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # Compute the gradient\n",
    "        gradient = np.dot(X.T, (h - y)) / y.size\n",
    "        \n",
    "        # Update the coefficients\n",
    "        theta -= alpha * gradient\n",
    "        \n",
    "        # Compute the cost\n",
    "        cost = cost_function(h, y)\n",
    "        \n",
    "        # Append the cost to the cost history\n",
    "        cost_history.append(cost)\n",
    "    \n",
    "    # Compute the predictions\n",
    "    y_pred = sigmoid(np.dot(X, theta))\n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    # Return the coefficients, cost history, and predictions\n",
    "    return theta, cost_history, y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fc62a43-e915-41c8-b13e-8dc2f3187093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression (raw data) from scratch: 0.6571428571428571\n",
      "Shape of y_test: (120,)\n",
      "Shape of predictions_scratch_norm: (280,)\n",
      "Shapes are different. Aligning shapes...\n",
      "Accuracy of Logistic Regression (normalized) from scratch: 0.6083333333333333\n",
      "Shape of y_test: (120,)\n",
      "Shape of predictions_scratch_std: (280,)\n",
      "Shapes are different. Aligning shapes...\n",
      "Accuracy of Logistic Regression (standardized) from scratch: 0.5833333333333334\n",
      "Accuracy of Logistic Regression (raw data) from sklearn: 0.6083333333333333\n",
      "Accuracy of Logistic Regression (normalized) from sklearn: 0.8416666666666667\n",
      "Accuracy of Logistic Regression (standardized) from sklearn: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Raw data\n",
    "theta_raw, _, predictions_scratch_raw = logistic_regression(X_train_raw.values, y_train.values, alpha=0.01, num_iter=1000)\n",
    "accuracy_scratch_raw = accuracy_score(y_train, predictions_scratch_raw)\n",
    "print(\"Accuracy of Logistic Regression (raw data) from scratch:\", accuracy_scratch_raw)\n",
    "\n",
    "# Normalization\n",
    "theta_normalized, _, predictions_scratch_norm = logistic_regression(X_train_norm, y_train, alpha=0.01, num_iter=1000)\n",
    "predictions_scratch_norm = np.round(predictions_scratch_norm)\n",
    "\n",
    "# Check and align shapes of y_test and predictions_scratch_norm\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "print(\"Shape of predictions_scratch_norm:\", predictions_scratch_norm.shape)\n",
    "\n",
    "if y_test.shape != predictions_scratch_norm.shape:\n",
    "    print(\"Shapes are different. Aligning shapes...\")\n",
    "    min_samples = min(y_test.shape[0], predictions_scratch_norm.shape[0])\n",
    "    y_test = y_test[:min_samples]\n",
    "    predictions_scratch_norm = predictions_scratch_norm[:min_samples]\n",
    "\n",
    "accuracy_scratch_norm = accuracy_score(y_test, predictions_scratch_norm)\n",
    "print(\"Accuracy of Logistic Regression (normalized) from scratch:\", accuracy_scratch_norm)\n",
    "\n",
    "\n",
    "# Standardization\n",
    "theta_standardized, _, predictions_scratch_std = logistic_regression(X_train_std, y_train, alpha=0.01, num_iter=1000)\n",
    "predictions_scratch_std = np.round(predictions_scratch_std)\n",
    "\n",
    "# Check and align shapes of y_test and predictions_scratch_std\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "print(\"Shape of predictions_scratch_std:\", predictions_scratch_std.shape)\n",
    "\n",
    "if y_test.shape != predictions_scratch_std.shape:\n",
    "    print(\"Shapes are different. Aligning shapes...\")\n",
    "    min_samples = min(y_test.shape[0], predictions_scratch_std.shape[0])\n",
    "    y_test = y_test[:min_samples]\n",
    "    predictions_scratch_std = predictions_scratch_std[:min_samples]\n",
    "\n",
    "accuracy_scratch_std = accuracy_score(y_test, predictions_scratch_std)\n",
    "print(\"Accuracy of Logistic Regression (standardized) from scratch:\", accuracy_scratch_std)\n",
    "\n",
    "\n",
    "# Logistic Regression using scikit-learn\n",
    "model_sklearn_raw = LogisticRegression(max_iter=1000)\n",
    "model_sklearn_raw.fit(X_train_raw, y_train)\n",
    "predictions_raw = model_sklearn_raw.predict(X_test_raw)\n",
    "accuracy_raw = accuracy_score(y_test, predictions_raw)\n",
    "print(\"Accuracy of Logistic Regression (raw data) from sklearn:\", accuracy_raw)\n",
    "\n",
    "model_sklearn_normalized = LogisticRegression(max_iter=1000)\n",
    "model_sklearn_normalized.fit(X_train_norm, y_train)\n",
    "predictions_normalized = model_sklearn_normalized.predict(X_test_norm)\n",
    "accuracy_normalized = accuracy_score(y_test, predictions_normalized)\n",
    "print(\"Accuracy of Logistic Regression (normalized) from sklearn:\", accuracy_normalized)\n",
    "model_sklearn_standardized = LogisticRegression(max_iter=1000)\n",
    "model_sklearn_standardized.fit(X_train_std, y_train)\n",
    "predictions_standardized = model_sklearn_standardized.predict(X_test_std)\n",
    "accuracy_standardized = accuracy_score(y_test, predictions_standardized)\n",
    "print(\"Accuracy of Logistic Regression (standardized) from sklearn:\", accuracy_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742630fc-8f65-42db-b814-833c4f8a4810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
